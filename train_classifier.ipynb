{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8d8887",
   "metadata": {
    "id": "6c8d8887",
    "outputId": "1cfbc649-1bdd-4fef-d784-96663caf5611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99078510873571% of samples were classified correctly for model1 !\n"
     ]
    }
   ],
   "source": [
    "import pickle #imports the pickle module, which provides functionality for serializing and deserializing Python objects\n",
    "import sklearn #Scikit-learn is a popular machine learning library in Python that provides various tools for data preprocessing, model selection, and evaluation\n",
    "'''\n",
    "'RandomForestClassifier' is an implementation of the random forest algorithm for classification tasks. \n",
    "It is a powerful ensemble learning method that combines multiple decision trees to make predictions\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier #imports the 'RandomForestClassifier' class from the 'sklearn.ensemble module'\n",
    "'''\n",
    "'train_test_split' is a utility function in 'scikit-learn' that splits a dataset into training and testing subsets. \n",
    "It is commonly used for evaluating machine learning models by training them on a portion of the data and \n",
    "testing their performance on the remaining data\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split #imports the 'train_test_split' function from the 'sklearn.model_selection' module\n",
    "'''\n",
    "'accuracy_score' is a metric in 'scikit-learn' that measures the accuracy of a classification model by comparing the predicted labels with the true labels. \n",
    "It is commonly used to evaluate the performance of classification models.\n",
    "'''\n",
    "from sklearn.metrics import accuracy_score # imports the accuracy_score function from the sklearn.metrics module\n",
    "import numpy as np # imports the 'numpy' module as a name np\n",
    "import os #imports the os module, which provides a way to interact with the operating system\n",
    "\n",
    "\n",
    "data_dict = pickle.load(open('./ASL2.pickle', 'rb')) #The deserialized data of 'ASL.pickle' is assigned to the variable 'data_dict', which now contains the dictionary structure that was saved in the file\n",
    "data_dir = './Single Hand Sign Datasets' #represents the path to the data directory that contains the dataset\n",
    "'''\n",
    "retrieves the value associated with the key 'data' from the 'data_dict' dictionary using the indexing operator []. \n",
    "It converts the retrieved data, which is a list or array-like structure, into a 'NumPy' array using the 'np.asarray()'\n",
    "'''\n",
    "data_one = np.asarray(data_dict['data'])\n",
    "'''\n",
    "this line retrieves the value associated with the key 'labels' from the 'data_dict' dictionary. \n",
    "It converts the retrieved data, which is a list or array-like structure, into a 'NumPy' array using 'np.asarray()'\n",
    "'''\n",
    "labels1 = np.asarray(data_dict['labels'])\n",
    "\n",
    "'''\n",
    "1. 'data_one': The input 'data' (features) to be split. This is a NumPy array or array-like object.\n",
    "2. 'labels1': The corresponding labels for the input data. This is a NumPy array or array-like object.\n",
    "3. 'test_size=0.2': The proportion of the data to be used for testing. In this case, it is set to 0.2, \n",
    "meaning 20% of the data will be allocated for testing, while 80% will be used for training.\n",
    "4. 'shuffle=True': This flag indicates whether to shuffle the data before splitting. By setting it to True, \n",
    "the data and labels will be randomly shuffled before the split.\n",
    "5. 'stratify=labels1': It ensures that the distribution of 'labels' in the 'training' and 'testing' sets is similar \n",
    "to the original distribution of labels.\n",
    "6. 'x_train': The training data (features) derived from 'data_one'. This will be used for training the random forest classifier.\n",
    "7. 'x_test': The testing data (features) derived from 'data_one'. This will be used for evaluating the trained classifier's performance.\n",
    "8. 'y_train': The training labels derived from 'labels1'. These are the corresponding labels for the training data.\n",
    "9. 'y_test': The testing labels derived from 'labels1'. These are the corresponding labels for the testing dat \n",
    "'''\n",
    "x_train, x_test, y_train, y_test, = train_test_split(data_one, labels1, test_size=0.2, shuffle=True, stratify=labels1)\n",
    "\n",
    "'''\n",
    "The line of code model1 = RandomForestClassifier() creates an instance of the RandomForestClassifier class from scikit-learn and assigns it to the variable model1\n",
    "'''\n",
    "model1 = RandomForestClassifier()\n",
    "\n",
    "'''\n",
    "The code model1.fit(x_train, y_train) trains the random forest classifier (model1) on the training data and corresponding labels.\n",
    "1. 'model1': The random forest classifier instance that was previously created using RandomForestClassifier().\n",
    "2. '.fit()': The 'fit()' method is called on the 'model1' object to train the classifier.\n",
    "3. 'x_train': The training data (features) that was previously split using 'train_test_split()'. This is a NumPy array or array-like object.\n",
    "4. 'y_train': The corresponding training labels. These are the target values or classes associated with the training data. Also a NumPy array or array-like object.\n",
    "'''\n",
    "model1.fit(x_train, y_train)\n",
    "\n",
    "'''\n",
    "The code 'y_predict = model1.predict(x_test)' uses the trained random forest classifier (model1) to make predictions on the testing data (x_test). \n",
    "1. 'y_predict': This variable is assigned for the predicted labels generated by the random forest classifier for the testing data.\n",
    "2. 'model1': The random forest classifier instance that was previously trained using the 'fit()' method.\n",
    "3. '.predict()': The 'predict()' method is called on the 'model1' object to generate predictions for the input data.\n",
    "4.  'x_test': The testing data (features) that was previously split using 'train_test_split()'. This is a NumPy array or array-like object.\n",
    "'''\n",
    "y_predict = model1.predict(x_test)\n",
    "\n",
    "'''\n",
    "The line of code 'score1 = accuracy_score(y_predict, y_test)' calculates the accuracy score of the predictions made by the \n",
    "random forest classifier (y_predict) compared to the true labels (y_test):\n",
    "1. 'score1': This variable is assigns the accuracy score computed based on the 'predicted labels (y_predict)' and the 'true labels (y_test)'.\n",
    "2. 'accuracy_score()': The 'accuracy_score()' function from 'scikit-learn' is called to calculate the accuracy score.\n",
    "3. 'y_predict': The predicted labels generated by the random forest classifier for the testing data.\n",
    "4. 'y_test': The true labels for the testing data.\n",
    "'''\n",
    "score1 = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print('{}% of samples were classified correctly for model1 !'.format(score1 * 100)) #prints the accuracy in percentage format\n",
    "\n",
    "f = open('model_ASL2.p', 'wb') #saves the model in the .pickle format\n",
    "pickle.dump({'model1': model1}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb2d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
